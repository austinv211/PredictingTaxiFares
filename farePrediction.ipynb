{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a function to get the real distance between to lat/long points\n",
    "- Manhattan distance should be useful, but I think we can do better with real distance\n",
    "- Here we compare a manual calculation to the geopy library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sin, cos, sqrt, atan2, radians\n",
    "import geopy.distance\n",
    "\n",
    "def geo_manhattan_distance(lat1, lat2, long1, long2):\n",
    "    \"\"\"\n",
    "    returns the manhattan distance between two geo points\n",
    "    \"\"\"\n",
    "    return abs(lat2 - lat1) + abs(long2 - long1)\n",
    "\n",
    "def geopy_dist(coord1, coord2):\n",
    "    try:\n",
    "        return geopy.distance.distance(coord1, coord2).kilometers\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2, m_const=3958.8):\n",
    "    lat1, lon1, lat2, lon2 = map(abs, [lat1, lon1, lat2, lon2])\n",
    "    lat1, lon1, lat2, lon2 = map(np.deg2rad, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1 \n",
    "    dlon = lon2 - lon1 \n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a)) \n",
    "    mi = m_const * c\n",
    "    return mi\n",
    "\n",
    "# filter functions to reduce the dataset\n",
    "def within_boundary(dataframe, boundary):\n",
    "    return (dataframe['pickup_longitude'] >= boundary[0]) & (dataframe['pickup_longitude'] <= boundary[1]) & \\\n",
    "            (dataframe['pickup_latitude'] >= boundary[2]) & (dataframe['pickup_latitude'] <= boundary[3]) & \\\n",
    "            (dataframe['dropoff_longitude'] >= boundary[0]) & (dataframe['dropoff_longitude'] <= boundary[1]) & \\\n",
    "            (dataframe['dropoff_latitude'] >= boundary[2]) & (dataframe['dropoff_latitude'] <= boundary[3])\n",
    "\n",
    "def not_at_airport(dataframe):\n",
    "    return ~((dataframe['pickup_to_jfk'] < 1) | (dataframe['dropoff_to_jfk'] < 1)) & \\\n",
    "            ~((dataframe['pickup_to_laguardia'] < 1) | (dataframe['dropoff_to_laguardia'] < 1))\n",
    "\n",
    "\n",
    "def has_passengers(dataframe):\n",
    "    return (dataframe['passenger_count'] != 0)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import our dataset\n",
    "- our dataset consists of several files:\n",
    "    - train.csv: our training data\n",
    "    - test.csv: our testing data\n",
    "    - sample_submissions.csv: A sample submission file in the correct format (columns key and fare_amount). This dummy file 'predicts' fare_amount to be $11.35 for all rows, which is the mean fare_amount from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Datasets...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>real_dist</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>pickup_to_jfk</th>\n",
       "      <th>dropoff_to_jfk</th>\n",
       "      <th>pickup_to_laguardia</th>\n",
       "      <th>dropoff_to_laguardia</th>\n",
       "      <th>dropoff_from_center</th>\n",
       "      <th>pickup_from_center</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11478</th>\n",
       "      <td>20.5</td>\n",
       "      <td>2</td>\n",
       "      <td>2.686101</td>\n",
       "      <td>16</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>2014</td>\n",
       "      <td>13.915098</td>\n",
       "      <td>12.568811</td>\n",
       "      <td>7.379848</td>\n",
       "      <td>4.717852</td>\n",
       "      <td>3.968604</td>\n",
       "      <td>2.067722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49496</th>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.755679</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>13.413561</td>\n",
       "      <td>13.053351</td>\n",
       "      <td>5.564542</td>\n",
       "      <td>7.511679</td>\n",
       "      <td>0.950833</td>\n",
       "      <td>3.698974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63585</th>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.115377</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>2015</td>\n",
       "      <td>13.928647</td>\n",
       "      <td>14.060379</td>\n",
       "      <td>7.214093</td>\n",
       "      <td>5.106556</td>\n",
       "      <td>5.152266</td>\n",
       "      <td>2.273114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>10.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.395700</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>2012</td>\n",
       "      <td>12.972420</td>\n",
       "      <td>14.122780</td>\n",
       "      <td>5.719373</td>\n",
       "      <td>7.063343</td>\n",
       "      <td>2.698994</td>\n",
       "      <td>3.069815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12389</th>\n",
       "      <td>7.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.580834</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>12.552576</td>\n",
       "      <td>13.063415</td>\n",
       "      <td>6.213803</td>\n",
       "      <td>6.272833</td>\n",
       "      <td>2.468924</td>\n",
       "      <td>2.174333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fare_amount  passenger_count  real_dist  hour  day  month  year  \\\n",
       "11478         20.5                2   2.686101    16   27      9  2014   \n",
       "49496         17.0                1   2.755679    11   18      4  2013   \n",
       "63585         17.0                1   3.115377    12   28      6  2015   \n",
       "826           10.5                1   1.395700    17   20      3  2012   \n",
       "12389          7.7                1   0.580834     3   21      1  2012   \n",
       "\n",
       "       pickup_to_jfk  dropoff_to_jfk  pickup_to_laguardia  \\\n",
       "11478      13.915098       12.568811             7.379848   \n",
       "49496      13.413561       13.053351             5.564542   \n",
       "63585      13.928647       14.060379             7.214093   \n",
       "826        12.972420       14.122780             5.719373   \n",
       "12389      12.552576       13.063415             6.213803   \n",
       "\n",
       "       dropoff_to_laguardia  dropoff_from_center  pickup_from_center  \n",
       "11478              4.717852             3.968604            2.067722  \n",
       "49496              7.511679             0.950833            3.698974  \n",
       "63585              5.106556             5.152266            2.273114  \n",
       "826                7.063343             2.698994            3.069815  \n",
       "12389              6.272833             2.468924            2.174333  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TOTAL_ROWS = 55423855\n",
    "\n",
    "DATA_FILES_PATH = 'projectDataFiles/'\n",
    "\n",
    "NYC_COORD = (40.7128, 74.0060)\n",
    "JFK_COORD = (40.6413, 73.7781)\n",
    "LAGUARDIA_COORD = (40.7769, 73.8740)\n",
    "\n",
    "# NYC Boundaries\n",
    "NYC_BOUNDARY = (-74.5, -72.8, 40.5, 41.8) # in format WEST, EAST, NORTH, SOUTH\n",
    "\n",
    "# training data types\n",
    "TRAINING_TYPES = {\n",
    "    'fare_amount': 'float32',\n",
    "    'pickup_datetime': 'str',\n",
    "    'pickup_longitude': 'float32',\n",
    "    'pickup_latitude': 'float32',\n",
    "    'dropoff_longitude': 'float32',\n",
    "    'dropoff_latitude': 'float32',\n",
    "    'passenger_count': 'uint8'\n",
    "}\n",
    "\n",
    "COLUMNS = list(TRAINING_TYPES.keys()) + ['real_dist']\n",
    "\n",
    "FEATURES = [item for item in COLUMNS if item != 'fare_amount']\n",
    "\n",
    "LABEL = 'fare_amount'\n",
    "\n",
    "def import_training_dataset_limit(file_path, row_limit=100000):\n",
    "    \"\"\"\n",
    "    function to import the dataset into a pandas dataframe.\n",
    "\n",
    "    Takes a row limit to limit the number of rows read.\n",
    "    \"\"\"\n",
    "    if row_limit:\n",
    "        return process_df(pd.read_csv(file_path, nrows=row_limit))\n",
    "    else:\n",
    "        return process_df(pd.read_csv(file_path))\n",
    "\n",
    "\n",
    "def get_df_list(file_path, chunksize=1000000):\n",
    "    df_list = []\n",
    "    for df_chunk in pd.read_csv(file_path, chunksize=chunksize, dtype=TRAINING_TYPES):\n",
    "        df_chunk = process_df(df_chunk)\n",
    "        df_list.append(df_chunk)\n",
    "    return df_list\n",
    "        \n",
    "def process_df(dataframe, train_data=True):\n",
    "    pd.set_option('use_inf_as_na', True)\n",
    "    dataframe['pickup_datetime'] = dataframe['pickup_datetime'].str.slice(0, 16)\n",
    "    dataframe['pickup_datetime'] = pd.to_datetime(dataframe['pickup_datetime'], utc=True, format='%Y-%m-%d %H:%M')\n",
    "    # the distance between the pickup and dropoff points\n",
    "    dataframe['real_dist'] = haversine(dataframe['pickup_latitude'], dataframe['pickup_longitude'], dataframe['dropoff_latitude'], dataframe['dropoff_longitude'])\n",
    "\n",
    "    # add the deconstructed date\n",
    "    dataframe['hour'] = dataframe['pickup_datetime'].dt.hour\n",
    "    dataframe['day'] = dataframe['pickup_datetime'].dt.day\n",
    "    dataframe['month'] = dataframe['pickup_datetime'].dt.month\n",
    "    dataframe['year'] = dataframe['pickup_datetime'].dt.year\n",
    "\n",
    "    # add the distances to the airports\n",
    "    dataframe['pickup_to_jfk'] = haversine(dataframe['pickup_latitude'], dataframe['pickup_longitude'], JFK_COORD[0], JFK_COORD[1])\n",
    "    dataframe['dropoff_to_jfk'] = haversine(dataframe['dropoff_latitude'], dataframe['dropoff_longitude'], JFK_COORD[0], JFK_COORD[1])\n",
    "    dataframe['pickup_to_laguardia'] = haversine(dataframe['pickup_latitude'], dataframe['pickup_longitude'], LAGUARDIA_COORD[0], LAGUARDIA_COORD[1])\n",
    "    dataframe['dropoff_to_laguardia'] = haversine(dataframe['dropoff_latitude'], dataframe['dropoff_longitude'], LAGUARDIA_COORD[0], LAGUARDIA_COORD[1])\n",
    "\n",
    "    # distance from center of new york\n",
    "    dataframe['dropoff_from_center'] = haversine(dataframe['dropoff_latitude'], dataframe['dropoff_longitude'], NYC_COORD[0], NYC_COORD[1])\n",
    "    dataframe['pickup_from_center'] = haversine(dataframe['pickup_latitude'], dataframe['pickup_longitude'], NYC_COORD[0], NYC_COORD[1])\n",
    "\n",
    "    # adding fare per mile\n",
    "    if train_data:\n",
    "        dataframe['fare_per_mile'] = dataframe['fare_amount'] / dataframe['real_dist']\n",
    "        \n",
    "    # limit to the boundary\n",
    "    dataframe = dataframe[within_boundary(dataframe, NYC_BOUNDARY) & has_passengers(dataframe) & not_at_airport(dataframe)].copy()\n",
    "\n",
    "    # drop uneccessary columns\n",
    "    dataframe.drop(['key', 'pickup_datetime', 'pickup_longitude', 'pickup_latitude', 'dropoff_latitude', 'dropoff_longitude'], axis=1, inplace=True)\n",
    "    dataframe.dropna(axis=1, how='any', inplace=True)\n",
    "    return dataframe\n",
    "\n",
    "def read_feathered_data(file_path):\n",
    "    return pd.read_feather(file_path)\n",
    "\n",
    "def feather_dataset(dataframe, file_out):\n",
    "    dataframe.to_feather(file_out)\n",
    "\n",
    "# import the dataset as a list of chunks, from here we can do our processing at a chunk level\n",
    "print('Importing Datasets...')\n",
    "# DATA_LIST = get_df_list(f'{DATA_FILES_PATH}train.csv')\n",
    "\n",
    "# train_split = int(len(DATA_LIST) * 0.8)\n",
    "\n",
    "# random.shuffle(DATA_LIST)\n",
    "\n",
    "# TRAINING_LIST = DATA_LIST[:train_split]\n",
    "\n",
    "# TEST = pd.concat(DATA_LIST[train_split:])\n",
    "\n",
    "# TRAINING_LIST[0].head()\n",
    "\n",
    "# import the dataset for testing \n",
    "DF = import_training_dataset_limit(f'{DATA_FILES_PATH}train.csv')\n",
    "\n",
    "DF.head()\n",
    "\n",
    "TRAIN, TEST = train_test_split(DF, test_size=0.2)\n",
    "\n",
    "TRAIN.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>real_dist</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>pickup_to_jfk</th>\n",
       "      <th>dropoff_to_jfk</th>\n",
       "      <th>pickup_to_laguardia</th>\n",
       "      <th>dropoff_to_laguardia</th>\n",
       "      <th>dropoff_from_center</th>\n",
       "      <th>pickup_from_center</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47970</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.803903</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>2014</td>\n",
       "      <td>13.468622</td>\n",
       "      <td>12.877165</td>\n",
       "      <td>5.484062</td>\n",
       "      <td>5.537908</td>\n",
       "      <td>3.212159</td>\n",
       "      <td>3.863885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61484</th>\n",
       "      <td>10.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3.502995</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2009</td>\n",
       "      <td>12.871857</td>\n",
       "      <td>14.346217</td>\n",
       "      <td>5.049871</td>\n",
       "      <td>4.178435</td>\n",
       "      <td>7.282764</td>\n",
       "      <td>3.809082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77936</th>\n",
       "      <td>6.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>2010</td>\n",
       "      <td>13.542083</td>\n",
       "      <td>13.542083</td>\n",
       "      <td>5.869239</td>\n",
       "      <td>5.869239</td>\n",
       "      <td>3.455426</td>\n",
       "      <td>3.455426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17298</th>\n",
       "      <td>7.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.315550</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2009</td>\n",
       "      <td>13.177572</td>\n",
       "      <td>12.557696</td>\n",
       "      <td>8.724756</td>\n",
       "      <td>7.417214</td>\n",
       "      <td>0.794867</td>\n",
       "      <td>0.520713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67942</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.765729</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>2013</td>\n",
       "      <td>13.494769</td>\n",
       "      <td>12.306820</td>\n",
       "      <td>6.141811</td>\n",
       "      <td>7.512410</td>\n",
       "      <td>0.751082</td>\n",
       "      <td>3.059539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fare_amount  passenger_count  real_dist  hour  day  month  year  \\\n",
       "47970          8.0                2   0.803903     5   11      8  2014   \n",
       "61484         10.9                1   3.502995     0    3      9  2009   \n",
       "77936          6.1                1   0.000000     8   21      8  2010   \n",
       "17298          7.7                1   1.315550    20    2      5  2009   \n",
       "67942         15.0                2   2.765729    17   21     10  2013   \n",
       "\n",
       "       pickup_to_jfk  dropoff_to_jfk  pickup_to_laguardia  \\\n",
       "47970      13.468622       12.877165             5.484062   \n",
       "61484      12.871857       14.346217             5.049871   \n",
       "77936      13.542083       13.542083             5.869239   \n",
       "17298      13.177572       12.557696             8.724756   \n",
       "67942      13.494769       12.306820             6.141811   \n",
       "\n",
       "       dropoff_to_laguardia  dropoff_from_center  pickup_from_center  \n",
       "47970              5.537908             3.212159            3.863885  \n",
       "61484              4.178435             7.282764            3.809082  \n",
       "77936              5.869239             3.455426            3.455426  \n",
       "17298              7.417214             0.794867            0.520713  \n",
       "67942              7.512410             0.751082            3.059539  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a SGD partial fit\n",
    "- SGD stands for stochastic gradient descent\n",
    "- Here we are feeding our chunks into the partial fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting SGD predictions...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def sgd_train(chunk_list, loss=\"squared_loss\"):\n",
    "    my_sgd_regressor = SGDRegressor(loss=loss)\n",
    "    my_sgd_regressor.n_iter = np.ceil(10**6 / len(TEST[LABEL]))\n",
    "    scaler = StandardScaler()\n",
    "    for chunk in chunk_list:\n",
    "        X_train = chunk[chunk.columns.difference([LABEL])]\n",
    "        scaler.fit(X_train)\n",
    "        my_sgd_regressor.partial_fit(scaler.transform(X_train), chunk[LABEL])\n",
    "    X_test = TEST[TEST.columns.difference([LABEL])]\n",
    "    y_predict = my_sgd_regressor.predict(scaler.transform(X_test))\n",
    "    return y_predict\n",
    "\n",
    "print('Getting SGD predictions...')\n",
    "#Y_PREDICT_SGD = sgd_train(TRAINING_LIST)\n",
    "Y_PREDICT_SGD = sgd_train([TRAIN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting RF Predictions...\n",
      "building tree 1 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 50\n",
      "building tree 3 of 50\n",
      "building tree 4 of 50\n",
      "building tree 5 of 50\n",
      "building tree 6 of 50\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n",
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n",
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   32.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from functools import reduce\n",
    "\n",
    "def gen_rf(X_train, y_train):\n",
    "    rf = RandomForestRegressor(n_estimators = 2, verbose=3)\n",
    "    rf.fit(X_train, y_train)\n",
    "    return rf\n",
    "\n",
    "def combine_rf(a, b):\n",
    "    a.estimators_ += b.estimators_\n",
    "    a.n_estimators = len(a.estimators_)\n",
    "    return a\n",
    "\n",
    "def rf_train(chunk_list):\n",
    "    rf_list = [gen_rf(chunk[chunk.columns.difference([LABEL])], chunk[LABEL]) for chunk in chunk_list]\n",
    "    rf_total = reduce(combine_rf, rf_list)\n",
    "    y_predict = rf_total.predict(TEST[TEST.columns.difference([LABEL])])\n",
    "    return y_predict\n",
    "\n",
    "def rf_train_warm_start(chunk_list, n_estimators = 5):\n",
    "    rf = RandomForestRegressor(n_estimators = n_estimators, verbose=2, warm_start=True)\n",
    "    for index, chunk in enumerate(chunk_list):\n",
    "        X_train = chunk[chunk.columns.difference([LABEL])]\n",
    "        rf.fit(X_train, chunk[LABEL])\n",
    "        if index != len(chunk_list) - 1:\n",
    "            rf.n_estimators += n_estimators\n",
    "    X_test = TEST[TEST.columns.difference([LABEL])]\n",
    "    y_predict = rf.predict(X_test)\n",
    "    return y_predict\n",
    "    \n",
    "\n",
    "print('Getting RF Predictions...')\n",
    "#Y_PREDICT_RF = rf_train_warm_start(TRAINING_LIST)\n",
    "Y_PREDICT_RF = rf_train_warm_start([TRAIN], n_estimators=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGB RMSE: 7.099097980021045\n",
      "RF RMSE: 3.7180514405873137\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "def calc_rmse(y_test, y_prediction):\n",
    "    # Calculating \"Mean Square Error\" (MSE):\n",
    "    mse = metrics.mean_squared_error(y_test, y_prediction)\n",
    "\n",
    "    # Using numpy sqrt function to take the square root and calculate \"Root Mean Square Error\" (RMSE)\n",
    "    return np.sqrt(mse)\n",
    "\n",
    "print(f'SGB RMSE: {calc_rmse(TEST[LABEL], Y_PREDICT_SGD)}')\n",
    "print(f'RF RMSE: {calc_rmse(TEST[LABEL], Y_PREDICT_RF)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
